{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## txt to dict in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated_Generative_Model_for_Industrial_Anomaly_Detection_via_Bidirectional_LSTM_and_Attention_Mechanism.pdf: ['Attention mechanism', 'Hidden Markov Model (HMM)', 'Local Outlier Factor (LOF)', 'Generative Adversarial Network (GAN)', 'Bidirectional Long Short-Term Memory (Bi-LSTM)', 'Attention Mechanism (AM)', 'GAN (Generative Adversarial Network)', 'AM-GAN', 'AMBi-GAN']\n",
      "Self-Learning_Sparse_PCA_for_Multimode_Process_Monitoring.pdf: ['elastic weight consolidation (EWC) with principal component analysis (PCA–EWC)', 'and synaptic intelligence (SI) are referenced in this paper.', 'There are no specific deep learning models or machine learning methods mentioned in this paper. Instead', 'the paper presents a self-learning sparse principal component analysis (SPCA) method that combines multiple modes for process monitoring. The method uses an augmented Lagrange function with surrogate loss', 'and employs the adaptive proximal gradient algorithm (APG) for optimization. The paper also introduces monitoring statistics for performance evaluation.SPCA-SI (Self-Learning Sparse PCA) - deep learning method', 'PCA-EWC (Elastic Weight Consolidation) - machine learning method', 'RPCA (Recursive Principal Component Analysis) - machine learning method', 'IMPPCA (Improved Multiple-Model Principal Component Analysis) - machine learning method', 'KDE (Kernel Density Estimation) - machine learning method']\n",
      "Weighted_Linear_Local_Tangent_Space_Alignment_via_Geometrically_Inspired_Weighted_PCA_for_Fault_Detection.pdf: ['WPCA', 'heat kernel matrix', 'graph Laplacian', 'Riemannian metric', 'Laplace-Beltrami operator- Weighted Locally Linear Tangent Space Alignment (WLLTSA)', 'Kernel Principal Component Analysis (KPCA)', 'Manifold Learning (used in reference to LLTSA and LLE)', 'Support Vector Data Description (SVDD)']\n",
      "An_Industrial_Multilevel_Knowledge_Graph-Based_LocalGlobal_Monitoring_for_Plant-Wide_Processes.pdf: ['PCA (Principal Component Analysis) is referenced in the paper for node status description. The following models or methods are also mentioned in the paper: normalized mutual information entropy', 'and χ2-distribution. However', 'these are not deep learning models or methods and not classified as machine learning models either.', 'The paper references the following deep learning models and machine learning methods:', \"Hotelling's T2 statistic\", 'Q statistic', 'F-distribution and χ2 distribution', 'Binary tree method (unintentionally formed)', 'Correlation matrix', 'Hyper-parameter configuration']\n",
      "Augmented_Multidimensional_Convolutional_Neural_Network_for_Industrial_Soft_Sensing.pdf: ['LeNet-5 (CNN)', 'MLP (machine learning)', 'Wasserstein GAN (GAN-based data augmentation method)', 'WGAN-GP (Wasserstein GAN with gradient penalty)', 'Inception (CNN)']\n",
      "A_Novel_Bayesian_Framework_With_Enhanced_Principal_Component_Analysis_for_Chemical_Fault_Diagnosis.pdf: ['1) eKPCA (Kernel Principal Component Analysis)', '2) RBF (Radial Basis Function)', '3) eNBM (Enhanced Naive Bayesian Model)', '4) Multivariate Gaussian kernel function- Dynamic LDA (DLDA)', 'Dynamic PCA (DPCA)', 'Support Vector Machines (SVM)', 'Multi-layer Perceptron (MLP)', 'Long Short-Term Memory (LSTM) ', 'Epsilon-Kernelized Principal Component Analysis (eKPCA)']\n",
      "Deep_Learning_for_Data_Modeling_of_Multirate_Quality_Variables_in_Industrial_Processes.pdf: ['Autoencoder (AE)', 'Stacked Autoencoder (SAE)', 'Back-propagation (BP) algorithm', 'Multirate Stacked Autoencoder (MR-SAE)The paper mentions the following deep learning models/machine learning methods:', 'Modified BP algorithm', 'Multirate Stacked AutoEncoder (MR-SAE)', 'MR-SAE (Multirate Stacked Autoencoder)', 'DBN (Deep Belief Network)', 'SAE (Stacked Autoencoder)', 'Mini-batch momentum gradient descent (optimization algorithm)']\n",
      "Detection_of_Site_to_Site_Variations_From_Volume_Measurement_Data_in_Multisite_Semiconductor_Testing.pdf: ['There are no specific deep learning models or machine learning methods referenced in this paper. The article focuses on identifying and addressing test and measurement issues in the semiconductor industry through the use of statistical techniques and visualization tools.', 'Central limit theorem', 'Z-score hypothesis testing', 'Quantile-quantile plot (QQ plot)', 'Regression analysis (used for QQ plot)']\n",
      "Granular-Based_Multilayer_Spatiotemporal_Network_With_Control_Gates_for_Energy_Prediction_of_Steel_Industry.pdf: ['Multilayer ST-LSTM', 'Template matching method', 'RNN (ESN)', 'MSSA-LSSVM', 'MSF-LSTM', 'STI-ESN- ESN', 'MSSA-LSSVM', 'MSF-LSTM']\n",
      "In-Process_Noise_Inspection_System_for_Product_Fault_Detection_in_a_Loud_Shop-Floor_Environment.pdf: ['Non-negative matrix factorization (NMF)', 'Gradient-descent-based update rule', 'Multiplicative update rule ', 'Cosine similarities ', 'Sum of squares']\n",
      "Joint_Distribution-Based_Test_Selection_for_Fault_Detection_and_Isolation_Under_Multiple_Faults_Condition.pdf: ['Multivariate JD', 'Deep joint distribution', 'Bernoulli distribution model', 'Deep copula functionDeep learning models and machine learning methods are not referenced in this paper.', 'Maximum Likelihood Estimation (MLE)', 'Gaussian copula function', 'Improved Discrete Binary PSO algorithm (IBPSO)IBPSO', 'BD', 'and JD.']\n",
      "An_Industrial_Process_Monitoring_Method_Based_on_Entropy_Projection_Transformation_Analysis.pdf: ['ReliefF algorithm', 'Entropy Projection Transformation Analysis (EPTA)', 'Kernel density estimation function', 'Second-order statistics (Q and Hotelling T2)', 'Relative entropy statistic (SRE)']\n",
      "A_Multiblock_Kernel_Dynamic_Latent_Variable_Model_for_Large-Scale_Industrial_Process_Monitoring.pdf: ['Multiblock Kernel DLV (MBKDLV) model', 'Kernelized dynamic latent variable (KDLV) modelThere are several machine learning methods referenced in the paper', 'but there are no specific deep learning models mentioned. Some of the machine learning methods referenced in the paper include:', 'Vector autoregressive model (VAR)', 'Multivariate least squares method', 'Radial basis function (RBF)']\n",
      "A_Novel_Quality-Related_Incipient_Fault_Detection_Method_Based_on_Canonical_Variate_Analysis_and_KullbackLeibler_Divergence_for_Large-Scale_Industrial_Processes.pdf: ['KLD (Kullback-Leibler Divergence)', 'CV A (Canonical Variate Analysis)', 'Bayesian inference- KLD', 'KPCA']\n",
      "A_Practical_Root_Cause_Diagnosis_Framework_for_Quality-Related_Faults_in_Manufacturing_Processes_With_Irregular_Sampling_Measurements.pdf: ['SIA-GRU', 'Attention network', 'CGC', 'Linear GC', 'LSTM-GC', 'GRU-GC1. k-nearest MI based variable division algorithm', 'SIA-GRU']\n",
      "Distributed_Robust_Process_Monitoring_Based_on_Optimized_Denoising_Autoencoder_With_Reinforcement_Learning.pdf: ['Stacked denoising autoencoder (SDAE)', 'Kernel density estimation (KDE)', 'Deep autoencoder (DAE)', 'Regression neural network- Distributed Autoencoder (DAE)', 'Local monitoring model', 'Neural Network models', 'RL-based NAS method', 'Regression Network model', 'ReLU activation function']\n",
      "Gated_Broad_Learning_System_Based_on_Deep_Cascaded_for_Soft_Sensor_Modeling_of_Industrial_Process.pdf: ['Ridge regression', 'Deep-BLS', 'Autoencoder (AE)', 'Deep Cascaded-Gated BLS- Deep Cascade-Gated Broad Learning System (DC-GBLS)', 'Broad Learning System (BLS)', 'Autoencoder (AE)', 'Variational Autoencoder (VAE)', 'Stacked Autoencoder (SAE)', 'Spatial-Temporal Attention LSTM (STA-LSTM)']\n",
      "Statistical_Process_Monitoring_Based_on_Collaboration_Preserving_Embedding.pdf: ['DPCA', 'LPP', 'JSPE', 'and nonlocal and multiple neighborhoods preserving embedding (NoMNPE)']\n",
      "Masked_Swin_Transformer_Unet_for_Industrial_Anomaly_Detection.pdf: ['CNN-based anomaly detection algorithms', 'Swin Transformer-based inpainting subnetwork', 'Convolution-based Unet network for discriminant subnetwork', 'L2loss and structural similarity (SSIM) loss for inpainting loss', 'Focal loss for discriminant subnetwork loss', 'continue at 3600 for references', '6783 in total- Swin Transformer', 'U-Net ', 'Convolutional Neural Networks (CNN)', 'Inpainting strategy ', 'Generative Adversarial Networks (GAN)', 'Autoencoders', 'BERT', 'Transformers for image recognition', 'Inpainting transformer', 'Medical transformer', 'SUNet', 'Masked autoencoders', 'Swin transformer UNet', 'Dense object detection.', 'Fully convolutional networks (FCNs)', 'Unet model', 'Deep convolutional autoencoder network model', 'Generative adversarial network (GAN)', 'Skip connected and adversarially trained encoder-decoder anomaly detection (Skip-GANomaly)', 'Deep autoencoding approach', 'Variational autoencoders', 'Deep CNN (DCNN)-based method', 'Visual Transformer', 'TransUNet model', 'L2 loss', 'Structural similarity (SSIM) loss', 'MSGMS (Multi-Scale Gaussian Mixture Model)', 'CutPaste (data enhancement-based strategy)']\n",
      "Multivariate_Time-Series_Prediction_in_Industrial_Processes_via_a_Deep_Hybrid_Network_Under_Data_Uncertainty.pdf: ['DCGNet', 'Bayesian theory-based optimization (BTO)', 'Here are the deep learning models or machine learning methods referenced in the paper:', 'CNN with a residual elimination module', 'Bi-GRU network', 'Bayesian theory-based hyperparameter optimization method', 'WaveNets long short term memory paradigm', 'Evolutionary-based deep convolutional neural network model', 'ARIMA algorithm for time series prediction', 'Deep LSTM networks', 'Deep and embedded learning approach for traffic flow prediction', 'Convolutional LSTM neural network autoencoders', 'DCGNet', 'Variational mode decomposition for short-term wind power interval prediction', 'Gated recurrent unit for news text classification', 'Discrete and continuous-time soft-thresholding for dynamic signal recovery', 'Deep residual shrinkage networks', 'Full attention-based Bi-GRU neural network', 'Hybrid Latin hypercube sampling and multiple linear regression', 'Particle swarm optimization-based CNN-LSTM networks', 'Bayesian optimization for accelerating hyper-parameter tuning', 'Intelligent PHM-based auxiliary decision framework', \"I'm sorry but I need the title of the paper to identify the deep learning models or machine learning methods referenced in it.\", 'Support vector machine', 'Extreme learning machine', 'Genetic algorithm', 'Artificial neural network', 'Autoregressive integrated moving average', 'Filter-based model', 'Encoder-decoder', 'Convolutional neural network (CNN)', 'Deep belief network', 'Recurrent neural network (RNN)', 'Hybrid models (e.g. Bayesian network + RNN', 'CNN-LSTM)', 'Maximal information coefficient (MIC)-based feature selection', 'Residual CNNs (RCNNs)', 'Gate Recurrent Units (GRUs)', 'DBN-GRU', '2D-ConvLSTM Autoencoder', 'DCGNet', 'VMD-GRU', 'EWT-NCULSTM', 'PCA', 'random search', 'particle swarm optimization (PSO)', 'enhanced gray wolf optimization (EGWO)', 'Bayesian theory-based optimization (BTO)', 'optimized BTO (OBTO)']\n",
      "Process_Monitoring_Using_Domain-Adversarial_Probabilistic_Principal_Component_Analysis_A_Transfer_Learning_Framework.pdf: ['Deep learning models:', 'No specific deep learning models referenced', 'but the paper uses a feature extractor and a domain classifier that are optimized together to obtain domain-invariant features across multiple domains.', 'Machine learning methods:', 'Variational inference', 'PPCA (Probabilistic Principal Component Analysis)', 'Logistic Regression', 'CUBO (Chi-Squared Upper Bound Optimal) algorithmDeep Adaptive Probabilistic Principal Component Analysis (DAPPCA)', 'Probabilistic Principal Component Analysis (PPCA)', 'Mixture Probabilistic Principal Component Analysis (MPPCA)', 'Probabilistic Slow Feature Analysis (PSFA)', 'continue at 3600 for references', '5568 in totalLinear regression model', 'DAPPCA and traditional PPCA are referenced as machine learning methods in this paper. Deep learning models were not referenced.', 'There are no explicit references to deep learning models or machine learning methods in this paper. However', 'the author\\'s research interests include \"data analytics\"', 'which could potentially involve the use of machine learning techniques.', 'Probabilistic Principal Component Analysis (PPCA)', 'Logistic regression (as domain classifier)', 'Domain adversarial Probabilistic Principal Component Analysis (DAPPCA)', 'Models and methods referenced in this paper include:', 'PPCA (Probabilistic Principal Component Analysis)', 'χ2-divergence', 'CUBO (χupper bound)', 'CHIVI algorithm (Convex-Concave procedure for Variational Inference)- Monte Carlo estimation', 'AdaGrad algorithm', 'Reverse PPCA (RPPCA)', 'Transfer learning framework (DAPPCA)']\n",
      "Safety_Poka_Yoke_in_Zero-Defect_Manufacturing_Based_on_Digital_Twins.pdf: ['Deep Neural Network (DNN)', 'Active Learning (AL)', 'Stacked Denoising Autoencoder (SDAE)', 'Convolutional Neural Network (CNN)', 'Domain Adaptation (DA)', 'Fault Recognition Algorithm Based on DANNs (Domain Adversarial Neural Networks)- DANN (Domain-Adversarial Neural Networks)', 'AL-DNN (Adversarial Learning Deep Neural Network)', 'random-DNN', 'entropy-DNN', 'BvSB-DNN', 'GD-CNN', 'Adagrad-CNN', 'WDCNN', 'MLP', 'No deep learning models or machine learning methods are referenced in this paper.', 'Active learning-deep neural network (AL-DNN)', 'Domain adversarial neural networks (DANN)', 'Gradient reversal layer (GRL)- DANN (Domain-Adversarial Neural Network)', 'AL-DNN (Active Learning-based Deep Neural Network)']\n",
      "A_Hybrid_First_Principles_and_Data-Driven_Process_Monitoring_Method_for_Zinc_Smelting_Roasting_Process.pdf: ['GCDL', 'KDE', 'PCA (Principal Component Analysis)', 'CSL (Common Subspace Learning)', 'KPCA (Kernel Principal Components Analysis)', 'MMD (Maximum Mean Difference)- PCA', 'KDE', 'RBR-based fault diagnosis model', 'PSO algorithm', 'PCA-CSL method', 'PCA model', 'SSA model', 'One-class support vector machine (SVM) model']\n",
      "Convolutional_Long_Short-Term_Memory_Autoencoder-Based_Feature_Learning_for_Fault_Detection_in_Industrial_Processes.pdf: ['ConvLSTM', 'CNN', 'DeconvLSTM', 'Selective residual block', 'Attention mechanism (AM)', 'Adam optimizer', 'Kernel density estimation (KDE)', 'KPCA', 'SDAE', 'ConvLSTM', 'CNN', 'and CLSTM-AE are all mentioned as deep learning models or machine learning methods in this paper.']\n",
      "Deep_Nonlinear_Dynamic_Feature_Extraction_for_Quality_Prediction_Based_on_Spatiotemporal_Neighborhood_Preserving_SAE.pdf: ['Spatial Neighborhood Preserving AE (SNP-AE)', 'Temporal Neighborhood Preserving AE (TNP-AE)', 'Spatiotemporal Neighborhood Preserving AE (STNP-AE)', 'Spatiotemporal Neighborhood Preserving SAE (STNP-SAE)- STNP-SAE (Spatio-Temporal Neighborhood Preserving Stacked Autoencoder)', 'BP algorithm (Backpropagation algorithm)', 'Support Vector Machine (SVM)', 'Multilayer Neural Network (MNN)', 'Stacked Autoencoder (SAE)', 'Deep Laplacian Autoencoder (DLapAE)', 'Nonlocal and Local Structure Preserving SAE (NLSP-SAE)', 'Spatial-Temporal Neighborhood Preserving SAE (STNP-SAE)']\n",
      "Fault_Detection_of_Wind_Turbines_by_Subspace_Reconstruction-Based_Robust_Kernel_Principal_Component_Analysis.pdf: ['PCA (Principal Component Analysis)', 'CPV (Cumulative Percentage of Variance)', 'Hotelling’s T2 statistic', 'SPE (Squared Prediction Error)', 'F-distribution', 'RPCA (Robust Principal Component Analysis)', 'RKPCA (Reinforced Kernel Principal Component Analysis)', 'RBF (Radial Basis Function) kernel', 'SVD (Singular Value Decomposition)1. SR-RKPCA-based fault detection', 'RKPCA method', 'KPCA technique', 'and AE are all referenced as machine learning methods in this paper.']\n",
      "Fault_Detection_Using_Structured_Joint_Sparse_Nonnegative_Matrix_Factorization.pdf: ['Joint Sparsity NMF', 'Graph Laplacian regularization', 'ADMM (Alternating Direction Method of Multipliers)', 'PCA (Principal Component Analysis)', 'ICA (Independent Component Analysis)', 'NMF (Non-negative Matrix Factorization)', 'SNMF (Sparse NMF)', 'GNMF (Graph Regularized NMF)', 'Kernel NMF', 'Deep NMF- PCA', 'SJSNMF']\n",
      "Multichannel_Diffusion_Graph_Convolutional_Network_for_the_Prediction_of_Endpoint_Composition_in_the_Converter_Steelmaking_Process.pdf: ['Spectral-domain theory-based graph convolutional layer', 'Multichannel diffusion graph convolutional network (MCDGCN)', 'Fully connected layer', 'Backpropagation algorithm', 'PLS (partial least squares)', 'ELM (extreme learning machine)', 'ANN (artificial neural network)', 'LSTM (long short-term memory)', 'DBN (deep belief network)', 'GCN (graph convolutional network)', 'MCDGCN (multichannel diffusion graph convolutional network)']\n",
      "Multimode_Process_Monitoring_and_Mode_Identification_Based_on_Multiple_Dictionary_Learning.pdf: ['sparse representation method', 'L2norm', 'mixed noise-based dictionary learning method', 'MDL method', 'LC-KSVD method', 'L1norm- K-SVD method', 'LC-KSVD method', 'Least-angle regression (LARS)', 'Orthogonal matching pursuit (OMP)', 'Multivariate ridge regression model', 'Univariate kernel estimator (KDE)', 'Gaussian kernel function', 'Sparse coding with OMP', 'RPCA (Robust Principal Component Analysis)', 'VLOF (Variable Local Outlier Factor)', 'LCDL (Low-rank and Compact Dictionary Learning)', 'L2 norm', 'MDL (Minimum Description Length)']\n",
      "Supervised_Deep_Belief_Network_for_Quality_Prediction_in_Industrial_Processes.pdf: ['Restricted Boltzmann Machine (RBM)', 'Deep Belief Network (DBN)', 'Gaussian unit-based RBM', 'Contrast Divergence (CD) algorithm', 'Supervised Deep Belief Network (SDBN)', 'Stacked RBMs- Stacked Restricted Boltzmann Machine (SRBM)', 'Backpropagation algorithm', 'Principal Component Regression (PCR)', 'Soft sensor models', 'SDBN-based soft sensor model', 'SAE (stacked autoencoder)', 'DBN (deep belief network)', 'SDBN-1 (DBN with quality variable added only at the first layer)', 'Hydrocracking process soft sensor model']\n",
      "Surface_Defects_Detection_Using_Non-convex_Total_Variation_Regularized_RPCA_With_Kernelization.pdf: ['Support vector machines (SVM)', 'Convolutional neural networks (CNNs)', 'Autoencoder', 'Generative adversarial networks (GAN)', 'Low-rank matrix decomposition', 'Nonconvex total variation regularization', 'Kernelized RPCA (KRPCA)', 'KRPCA-NTV model', 'Alternating direction method of multipliers (ADMM) for optimization.- Kernel Canonical Correlation Analysis (KCCA)', 'Kernelized Robust Principal Component Analysis with Non-convex Total Variation constraint (KRPCA-NTV)', 'There are no specific deep learning models or machine learning methods mentioned in this paper. The paper mainly discusses the performance of various methods on surface defect detection using different techniques and components. The techniques and components mentioned in the paper include KCCA', 'kernelization', 'nonconvex TV', 'postprocessing', 'and various feature descriptors such as Gabor feature and HOG feature.']\n",
      "Intelligent_Process_Monitoring_of_Laser-Induced_Graphene_Production_With_Deep_Transfer_Learning.pdf: ['Max-pooling layer', 'Unpooling layer', 'Deconvolutional layer', 'Convolutional Deep Belief Network (CDBN)', 'Gaussian Convolutional-Restricted Bozeman Machine (GCRBM)', 'Contrastive Divergence algorithm', 'Convolutional Denoising Autoencoder (CDAE)CDAE (Convolutional Denoising Autoencoder)', 'GCDBN (Gaussian-Contrastive Deep Belief Network)', 'binary CDBN', 'CNN (LeNet-5)', 'SVM (Support Vector Machine)']\n",
      "Sparse_and_Time-Varying_Predictive_Relation_Extraction_for_Root_Cause_Quantification_of_Nonstationary_Process_Faults.pdf: ['Lasso ', 'Elastic Net (EN)', 'RLS', 'Kalman filtering', 'Variational Bayes (VB)', 'Weighted Causal Prediction (WCP) model', 'Taylor expansion technique- LMS algorithm ', 'Subgradient method ', 'Convex optimization ', 'L1 norm penalty ', 'L2 norm penalty', 'STE (Symbolic Transfer Entropy)', 'LG (Linear Granger causality)', 'NG (Nonlinear Granger causality)', 'MTCMS (Modified Temporal Convolution and Multihead Self-Attention)', 'STPRE (Sparse Temporal Partial Correlation-based Root Cause Identification)', 'STPRE (proposed method)', 'NG (deep learning-based comparison model)', 'MTCMS (deep learning-based comparison model)', 'TPRE (comparison model)', 'LMS-WCP (comparison model)']\n",
      "Stationary_Mapping_Based_Generalized_Monitoring_Scheme_for_Industrial_Processes_With_Mixed_Operational_Stages.pdf: ['continue at 2898 for references', '9062 in total- Kernel density estimation (KDE)', 'Mutual information criterion (MIC)There are several machine learning methods mentioned in this paper', 'including:', 'Vector error correction (VEC) model', 'Ordinary least squares (OLS)', 'Detrended fluctuation analysis (DFA)', 'continue at 4335 for references', '9062 in total- Deep learning models or machine learning methods are not explicitly mentioned in the paper.- K-means ', 'SMPCA ', 'GSSFA ', 'TBM ', 'GCA ', 'DFR (Dynamic Factor Regression)', 'PCA (Principal Component Analysis)', 'LAS-based method', 'MWKDE. There is no specific mention of deep learning models or machine learning methods in this paper.']\n"
     ]
    }
   ],
   "source": [
    "# read .txt file\n",
    "import re\n",
    "import json\n",
    "input_dir = 'resources/txt/input.txt'\n",
    "file_block_delim = 'Leon424_new_message\\n'\n",
    "file_line_delim = '\\n'\n",
    "this_turn_dir = 'resources/json/this_turn.json'\n",
    "next_turn_dir = 'resources/json/next_turn.json'\n",
    "\n",
    "\n",
    "\"\"\"_txt_structure_\n",
    "Leon424_new_message\n",
    "Integrated_Generative_Model_for_Industrial_Anomaly_Detection_via_Bidirectional_LSTM_and_Attention_Mechanism.pdf\n",
    "1. Hidden Markov model (HMM)\n",
    "2. Local Outlier Factor (LOF)\n",
    "3. Generative Adversarial Network (GAN)\n",
    "4. Bidirectional Long Short-Term Memory (LSTM)\n",
    "5. Attention Mechanism (AM)\n",
    "\n",
    "Leon424_new_message\n",
    "Integrated_Generative_Model_for_Industrial_Anomaly_Detection_via_Bidirectional_LSTM_and_Attention_Mechanism.pdf\n",
    "- LSTM\n",
    "- GAN\n",
    "- Attention mechanism\n",
    "\"\"\"\n",
    "\n",
    "def delete_ordered_list_number(input_text):\n",
    "    if re.match(r'^\\d+\\. ', input_text):\n",
    "        return input_text[re.match(r'^\\d+\\. ', input_text).span()[1]:]\n",
    "    else:\n",
    "        return input_text\n",
    "\n",
    "def delete_unordered_list_symbol(input_text):\n",
    "    if re.match(r'- ', input_text):\n",
    "        return input_text[re.match(r'- ', input_text).span()[1]:]\n",
    "    else:\n",
    "        return input_text\n",
    "\n",
    "def delete_space_at_the_beginning(input_text):\n",
    "    if re.match(r'^\\s+', input_text):\n",
    "        return input_text[re.match(r'^\\s+', input_text).span()[1]:]\n",
    "    else:\n",
    "        return input_text\n",
    "\n",
    "def convert_comma_to_list(input_text):\n",
    "    return input_text.split(',')\n",
    "\n",
    "def delete_included_string_in_set(input_set):\n",
    "    original_set = input_set.copy()\n",
    "    for x in original_set:\n",
    "        for y in original_set:\n",
    "            if x in y and x != y and x in input_set:\n",
    "                input_set.remove(x)\n",
    "    return input_set\n",
    "\n",
    "def delete_same_string_lower_in_set(input_set):\n",
    "    original_set = input_set.copy()\n",
    "    delete_dict = {}\n",
    "    for x in original_set:\n",
    "        for y in original_set:\n",
    "            if x.lower() == y.lower() and x != y :\n",
    "                delete_dict[x.lower()] = x\n",
    "    for x in delete_dict.values():\n",
    "        if x in input_set:\n",
    "            input_set.remove(x)\n",
    "    return input_set\n",
    "\n",
    "def txt_to_json(input_dir, file_block_delim, file_line_delim, this_turn_dir, next_turn_dir):\n",
    "    with open(input_dir, 'r') as f:\n",
    "        input_txt = f.read()\n",
    "    input_text_list = input_txt.split(file_block_delim)[1:]\n",
    "    input_text_lists = [x.split(file_line_delim) for x in input_text_list]\n",
    "    input_text_dict = {}\n",
    "\n",
    "    for x in input_text_lists:\n",
    "        if x[0] not in input_text_dict.keys():\n",
    "            input_text_dict[x[0]] = {}\n",
    "            message_index = 0\n",
    "        else:\n",
    "            if 'for references' in x[1].lower() and 'break' in x[1].lower():\n",
    "                continue\n",
    "            message_index += 1\n",
    "        input_text_dict[x[0]][f'message_{message_index}'] = []\n",
    "        for y in x[1:]:\n",
    "            if y != '':\n",
    "                y = delete_ordered_list_number(y)\n",
    "                y = delete_unordered_list_symbol(y)\n",
    "                if ',' in y:\n",
    "                    y = convert_comma_to_list(y)\n",
    "                    \n",
    "                else:\n",
    "                    y = [y]\n",
    "                y = [delete_space_at_the_beginning(z) for z in y]\n",
    "                input_text_dict[x[0]][f'message_{message_index}'] += y\n",
    "    input_text_dict = {\n",
    "        x: {y_k: y_v for y_k, y_v in y.items() if y_k !='message_0'} for x, y in input_text_dict.items()\n",
    "    }\n",
    "    input_text_dict_set = {\n",
    "        x: list([value  for z in y.values() for value in z]) for x, y in input_text_dict.items()\n",
    "    }\n",
    "    input_text_dict_set = {\n",
    "        x: delete_same_string_lower_in_set(delete_included_string_in_set(y)) for x, y in input_text_dict_set.items()\n",
    "    }\n",
    "    input_text_dict_set_num = {\n",
    "        x: len(y) for x, y in input_text_dict_set.items()\n",
    "    }\n",
    "\n",
    "    this_turn_dict = {}\n",
    "    next_turn_dict = {}\n",
    "    for key, value in input_text_dict_set.items(): \n",
    "        if input_text_dict_set_num[key] > 10:\n",
    "            next_turn_dict[key] = value\n",
    "        else:\n",
    "            this_turn_dict[key] = value\n",
    "\n",
    "    for key, value in this_turn_dict.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "\n",
    "    for key, value in next_turn_dict.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "    with open(this_turn_dir, 'w') as f:\n",
    "        json.dump(this_turn_dict, f ,indent=4)\n",
    "\n",
    "    with open(next_turn_dir,'w') as f:\n",
    "        json.dump(next_turn_dict, f, indent= 4)\n",
    "\n",
    "txt_to_json(input_dir, file_block_delim, file_line_delim, this_turn_dir, next_turn_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes_Masked_Swin_Transformer_Unet_for_Industrial_Anomaly_Detection.pdf: 17\n",
      "uncertain_Masked_Swin_Transformer_Unet_for_Industrial_Anomaly_Detection.pdf: 17\n",
      "yes_Multivariate_Time-Series_Prediction_in_Industrial_Processes_via_a_Deep_Hybrid_Network_Under_Data_Uncertainty.pdf: 23\n",
      "uncertain_Multivariate_Time-Series_Prediction_in_Industrial_Processes_via_a_Deep_Hybrid_Network_Under_Data_Uncertainty.pdf: 23\n",
      "yes_Process_Monitoring_Using_Domain-Adversarial_Probabilistic_Principal_Component_Analysis_A_Transfer_Learning_Framework.pdf: 9\n",
      "uncertain_Process_Monitoring_Using_Domain-Adversarial_Probabilistic_Principal_Component_Analysis_A_Transfer_Learning_Framework.pdf: 17\n",
      "yes_Safety_Poka_Yoke_in_Zero-Defect_Manufacturing_Based_on_Digital_Twins.pdf: 7\n",
      "uncertain_Safety_Poka_Yoke_in_Zero-Defect_Manufacturing_Based_on_Digital_Twins.pdf: 12\n",
      "yes_A_Hybrid_First_Principles_and_Data-Driven_Process_Monitoring_Method_for_Zinc_Smelting_Roasting_Process.pdf: 4\n",
      "uncertain_A_Hybrid_First_Principles_and_Data-Driven_Process_Monitoring_Method_for_Zinc_Smelting_Roasting_Process.pdf: 8\n",
      "yes_Convolutional_Long_Short-Term_Memory_Autoencoder-Based_Feature_Learning_for_Fault_Detection_in_Industrial_Processes.pdf: 4\n",
      "uncertain_Convolutional_Long_Short-Term_Memory_Autoencoder-Based_Feature_Learning_for_Fault_Detection_in_Industrial_Processes.pdf: 6\n",
      "yes_Deep_Nonlinear_Dynamic_Feature_Extraction_for_Quality_Prediction_Based_on_Spatiotemporal_Neighborhood_Preserving_SAE.pdf: 3\n",
      "uncertain_Deep_Nonlinear_Dynamic_Feature_Extraction_for_Quality_Prediction_Based_on_Spatiotemporal_Neighborhood_Preserving_SAE.pdf: 8\n",
      "yes_Fault_Detection_of_Wind_Turbines_by_Subspace_Reconstruction-Based_Robust_Kernel_Principal_Component_Analysis.pdf: 5\n",
      "uncertain_Fault_Detection_of_Wind_Turbines_by_Subspace_Reconstruction-Based_Robust_Kernel_Principal_Component_Analysis.pdf: 7\n",
      "yes_Fault_Detection_Using_Structured_Joint_Sparse_Nonnegative_Matrix_Factorization.pdf: 3\n",
      "uncertain_Fault_Detection_Using_Structured_Joint_Sparse_Nonnegative_Matrix_Factorization.pdf: 8\n",
      "yes_Multichannel_Diffusion_Graph_Convolutional_Network_for_the_Prediction_of_Endpoint_Composition_in_the_Converter_Steelmaking_Process.pdf: 5\n",
      "uncertain_Multichannel_Diffusion_Graph_Convolutional_Network_for_the_Prediction_of_Endpoint_Composition_in_the_Converter_Steelmaking_Process.pdf: 6\n",
      "yes_Multimode_Process_Monitoring_and_Mode_Identification_Based_on_Multiple_Dictionary_Learning.pdf: 9\n",
      "uncertain_Multimode_Process_Monitoring_and_Mode_Identification_Based_on_Multiple_Dictionary_Learning.pdf: 8\n",
      "yes_Supervised_Deep_Belief_Network_for_Quality_Prediction_in_Industrial_Processes.pdf: 7\n",
      "uncertain_Supervised_Deep_Belief_Network_for_Quality_Prediction_in_Industrial_Processes.pdf: 7\n",
      "yes_Surface_Defects_Detection_Using_Non-convex_Total_Variation_Regularized_RPCA_With_Kernelization.pdf: 5\n",
      "uncertain_Surface_Defects_Detection_Using_Non-convex_Total_Variation_Regularized_RPCA_With_Kernelization.pdf: 10\n",
      "yes_Intelligent_Process_Monitoring_of_Laser-Induced_Graphene_Production_With_Deep_Transfer_Learning.pdf: 7\n",
      "uncertain_Intelligent_Process_Monitoring_of_Laser-Induced_Graphene_Production_With_Deep_Transfer_Learning.pdf: 4\n",
      "yes_Sparse_and_Time-Varying_Predictive_Relation_Extraction_for_Root_Cause_Quantification_of_Nonstationary_Process_Faults.pdf: 11\n",
      "uncertain_Sparse_and_Time-Varying_Predictive_Relation_Extraction_for_Root_Cause_Quantification_of_Nonstationary_Process_Faults.pdf: 10\n",
      "yes_Stationary_Mapping_Based_Generalized_Monitoring_Scheme_for_Industrial_Processes_With_Mixed_Operational_Stages.pdf: 4\n",
      "uncertain_Stationary_Mapping_Based_Generalized_Monitoring_Scheme_for_Industrial_Processes_With_Mixed_Operational_Stages.pdf: 13\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "\n",
    "\"\"\"_json_structure_\n",
    "{\n",
    "\"Masked_Swin_Transformer_Unet_for_Industrial_Anomaly_Detection.pdf\": {\n",
    "    \"CNN-based anomaly detection algorithms\": \"Yes.\",\n",
    "    \"CutPaste (data enhancement-based strategy)\": \"Uncertain\"\n",
    "}, \n",
    "\"Multivariate_Time-Series_Prediction_in_Industrial_Processes_via_a_Deep_Hybrid_Network_Under_Data_Uncertainty.pdf\": {\n",
    "    \"DCGNet\": \"Uncertain. Please provide more context or information.\",\n",
    "\"\"\"\n",
    "\n",
    "input_dir = 'resources/json/message_output.json'\n",
    "output_folder = 'resources/json/'\n",
    "\n",
    "def get_yes_uncertain_json(input_dir, output_folder):\n",
    "    with open(input_dir, 'r') as f:\n",
    "        result_dict = json.load(f)\n",
    "\n",
    "    yes_dict = {}\n",
    "    uncertain_dict = {}\n",
    "\n",
    "    for key, value in result_dict.items():\n",
    "        yes_dict[key] = []\n",
    "        uncertain_dict[key] = []\n",
    "        for v_k, v_v in value.items():\n",
    "            if 'yes' in v_v.lower():\n",
    "                yes_dict[key].append(v_k)\n",
    "            else: \n",
    "                uncertain_dict[key].append(v_k)\n",
    "\n",
    "    for key, value in yes_dict.items():\n",
    "        print(f'yes_{key}: {len(value)}')\n",
    "        print(f'uncertain_{key}: {len(uncertain_dict[key])}') \n",
    "\n",
    "    with open(f'{output_folder}yes_dict.json', 'w') as f:\n",
    "        json.dump(yes_dict, f, indent=4)\n",
    "\n",
    "get_yes_uncertain_json(input_dir, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv\n",
    "import os \n",
    "\n",
    "\n",
    "input_folder = 'resources/json/'\n",
    "json_dir_list = ['this_turn.json', 'yes_dict.json']\n",
    "output_dir = os.path.join(input_folder, 'final_output.json')\n",
    "def combine_json(input_folder, json_dir_list, output_dir):\n",
    "\n",
    "    for i, json_dir in enumerate(json_dir_list):\n",
    "        file_dir = os.path.join(input_folder, json_dir)\n",
    "        with open(file_dir, 'r') as f:\n",
    "            if i == 0:\n",
    "                result_dict = json.load(f)\n",
    "            else:\n",
    "                result_dict.update(json.load(f))\n",
    "\n",
    "    with open(output_dir, 'w') as f:\n",
    "        json.dump(result_dict, f, indent=4)\n",
    "\n",
    "combine_json(input_folder, json_dir_list, output_dir)\n",
    "\n",
    "# # write json to csv\n",
    "# with open('final_output.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['name', 'message'])\n",
    "#     for key, value in result_dict.items():\n",
    "#         writer.writerow([key, ', '.join(value)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json to csv\n",
    "\n",
    "# import csv\n",
    "# import json\n",
    "\n",
    "# with open('final_output.json', 'r') as f:\n",
    "#     result_dict = json.load(f)\n",
    "# with open('final_output.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['name', 'message'])\n",
    "#     for key, value in result_dict.items():\n",
    "#         writer.writerow([key, ', '.join(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Monitoring Using Domain-Adversarial Probabilistic Principal Component Analysis: A Transfer Learning Framework\n",
      "Toward Interpretable Process Monitoring Slow Feature Analysis-Aided Autoencoder for Spatiotemporal Process Feature Learning\n",
      "### Manifold learning\n",
      "### Factorization\n",
      "Interval-Valued-Based Stacked Attention Autoencoder Model for Process Monitoring and Fault Diagnosis of Nonlinear Uncertain Systems\n",
      "Fault Diagnosis of Unseen Modes in Chemical Processes Based on Labeling and Class Progressive Adversarial Learning\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "input_md_dir = 'resources/md/review.md'\n",
    "input_json_dir = 'resources/json/final_output.json'\n",
    "output_dir = 'resources/csv/final_output.csv'\n",
    "\n",
    "\"\"\"_md_structure_\n",
    "# Detection\n",
    "\n",
    "## Transfer learning\n",
    "\n",
    "Process Monitoring Using Domain-Adversarial Probabilistic Principal Component Analysis: A Transfer Learning Framework, IEEE Transactions on Industrial Informatics, 2023\n",
    "\n",
    "综述：文章提出了一种新的基于PPCA的迁移学习方法DAPPCA，利用PPCA进行特征提取，再通过logistic对提取到的特征进行所属域分类。PPCA特征提取器和域分类器之间的对抗能够使模型提取出各个域之间的共同特征，实现知识的迁移。变分推断用于训练模型，得到模型的参数。DAPPCA主要用于解决新的过程模式缺少故障数据的问题，在数值数据和工业数据上的测试结果证明了其能够提高对新过程模式的故障探测能力。\n",
    "\n",
    "模型图：![image.png](review_files\\attach_2_image.png)\n",
    "\n",
    "案例数据：\n",
    "- Simulated example\n",
    "- Electrical Submersible Pump (ESP) \n",
    "\n",
    "\n",
    "Safety Poka Yoke in Zero-Defect Manufacturing Based on Digital Twins, IEEE Transactions on Industrial Informatics, 2023\n",
    "\n",
    "综述：在这篇文章中，作者提出了基于主动学习-深度神经网络（AL-DNN）和领域对抗神经网络（DANN）的设备故障探测和诊断算法。此外，还为智能制造管理设计了一个数字孪生车间管理和控制系统。AL-DNN首先通过SDAE-based DNN以无监督的方式进行特征提取，再通过主动学习对提取到的特征进行故障探测。DANN通过域分类器和故障分类器之间的对抗提取域之间的通用特征。实验探索表明，AL-DNN算法的准确率高达99.248%，DANN的准确率可以提高20.256%，与传统算法相比具有更高的准确性。\n",
    "\n",
    "模型图：![image.png](review_files\\attach_3_image.png)\n",
    "![image-2.png](review_files\\attach_3_image-2.png)\n",
    "\n",
    "案例数据：\n",
    "- Case Western Reserve University bearing dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"paper name difference\n",
    "md: Safety Poka Yoke in Zero-Defect Manufacturing Based on Digital Twins\n",
    "json: Masked_Swin_Transformer_Unet_for_Industrial_Anomaly_Detection.pdf\n",
    "\"\"\"\n",
    "def if_delete_from_list(string):\n",
    "    if string == '':\n",
    "        return True\n",
    "    if '综述' in string:\n",
    "        return True\n",
    "    if '模型图' in string:\n",
    "        return True\n",
    "    if string.startswith('![image'):\n",
    "        return True\n",
    "    if '案例数据' in string:\n",
    "        return True\n",
    "    if string.startswith('-'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def write_models_to_csv_hierarchy(input_md_dir, input_json_dir, output_dir):\n",
    "        \n",
    "    with open(input_md_dir, 'r') as f:\n",
    "        input_text = f.read()\n",
    "    input_list = input_text.split('\\n')\n",
    "    input_list = [x for x in input_list if if_delete_from_list(x) == False]\n",
    "    output_dict = {}\n",
    "\n",
    "    for x in input_list:\n",
    "        if x.startswith('# '):\n",
    "            present_first_level = x[2:]\n",
    "            present_second_level = ''\n",
    "        elif x.startswith('## '):\n",
    "            present_second_level = x[3:]\n",
    "        else:\n",
    "            title = x.split(',')[0]\n",
    "            output_dict[title] = [present_first_level, present_second_level]\n",
    "\n",
    "    hierarchy_dict = {}\n",
    "    for key, value in output_dict.items():\n",
    "        if value[0] not in hierarchy_dict.keys():\n",
    "            hierarchy_dict[value[0]] = {}\n",
    "        if value[1] not in hierarchy_dict[value[0]].keys():\n",
    "            hierarchy_dict[value[0]][value[1]] = []\n",
    "        hierarchy_dict[value[0]][value[1]].append(key)\n",
    "\n",
    "    with open(input_json_dir, 'r') as f:\n",
    "        model_name_dict = json.load(f)\n",
    "\n",
    "    with open(output_dir, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for key, value in hierarchy_dict.items():\n",
    "            writer.writerow([key, 'relevant model'])\n",
    "            for paper_list in value.values():\n",
    "                for paper in paper_list:\n",
    "                    try:\n",
    "                        writer.writerow([paper, ', '.join(model_name_dict[paper.replace(' ', '_')+'.pdf'])])\n",
    "                    except:\n",
    "                        print(paper)\n",
    "\n",
    "write_models_to_csv_hierarchy(input_md_dir, input_json_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
